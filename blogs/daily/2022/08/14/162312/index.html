<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#0078d4"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#0078d4">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css" integrity="sha256-Z1K5uhUaJXA7Ll0XrZ/0JhX4lAtZFpT6jkKrEDT0drU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"hetan697.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.14.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"flat"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"utterances","storage":true,"lazyload":true,"nav":null,"activeClass":"utterances"},"stickytabs":true,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInDown"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="介绍了将 When we disco 三渲二的历程主要步骤与相关问题，成功的有 AnimeGANv3 和 DCT-Net。文章全文偏长，没用的失败经历居多；如时间紧迫，只看上述成功的两节即可。">
<meta property="og:type" content="article">
<meta property="og:title" content="When we disco 三渲二">
<meta property="og:url" content="http://hetan697.github.io/blogs/daily/2022/08/14/162312/index.html">
<meta property="og:site_name" content="Hetan的博客">
<meta property="og:description" content="介绍了将 When we disco 三渲二的历程主要步骤与相关问题，成功的有 AnimeGANv3 和 DCT-Net。文章全文偏长，没用的失败经历居多；如时间紧迫，只看上述成功的两节即可。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://hetan697.github.io/blogs/daily/2022/08/14/162312/example.jpg">
<meta property="og:image" content="http://hetan697.github.io/blogs/daily/2022/08/14/162312/20220814_164614_image.png">
<meta property="og:image" content="http://hetan697.github.io/blogs/daily/2022/08/14/162312/20220814_164429_image.png">
<meta property="og:image" content="http://hetan697.github.io/blogs/daily/2022/08/14/162312/example_source.jpg">
<meta property="og:image" content="http://hetan697.github.io/blogs/daily/2022/08/14/162312/example_source_output.jpg">
<meta property="og:image" content="http://hetan697.github.io/blogs/daily/2022/08/14/162312/replicate-prediction-23anxtekzbewnhsuyumjnfclyy.png">
<meta property="og:image" content="http://hetan697.github.io/blogs/daily/2022/08/14/162312/5421.jpg">
<meta property="article:published_time" content="2022-08-14T08:23:12.000Z">
<meta property="article:modified_time" content="2023-01-28T08:08:57.177Z">
<meta property="article:author" content="Hetan">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://hetan697.github.io/blogs/daily/2022/08/14/162312/example.jpg">


<link rel="canonical" href="http://hetan697.github.io/blogs/daily/2022/08/14/162312/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://hetan697.github.io/blogs/daily/2022/08/14/162312/","path":"blogs/daily/2022/08/14/162312/","title":"When we disco 三渲二"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>When we disco 三渲二 | Hetan的博客</title>
  

  <script src="/js/third-party/analytics/baidu-analytics.js"></script>
  <script async src="https://hm.baidu.com/hm.js?9d3d45b6aa0aa3c74a095aba4384c50e"></script>





  <script async defer data-website-id="" src=""></script>

  <script defer data-domain="" src=""></script>

  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Hetan的博客</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/blogs/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-个人页"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>个人页</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8A%A8%E6%9C%BA"><span class="nav-number">1.</span> <span class="nav-text">动机</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8-Deep-Dream-Generator-%E5%A4%B1%E8%B4%A5"><span class="nav-number">2.</span> <span class="nav-text">使用 Deep Dream Generator (失败)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8-AnimeGANv2-%E5%A4%B1%E8%B4%A5"><span class="nav-number">3.</span> <span class="nav-text">使用 AnimeGANv2 (失败)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#paddle-%E4%BB%A3%E7%A0%81"><span class="nav-number">3.1.</span> <span class="nav-text">paddle 代码</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#0%E3%80%81BUG"><span class="nav-number">3.1.1.</span> <span class="nav-text">0、BUG</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1%E3%80%81%E5%AE%89%E8%A3%85PaddleHub"><span class="nav-number">3.1.2.</span> <span class="nav-text">1、安装PaddleHub</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2%E3%80%81%E8%AE%BE%E7%BD%AEGPU%E7%8E%AF%E5%A2%83"><span class="nav-number">3.1.3.</span> <span class="nav-text">2、设置GPU环境</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3%E3%80%81%E5%AF%BC%E5%85%A5%E7%9B%B8%E5%BA%94%E7%9A%84%E5%BA%93"><span class="nav-number">3.1.4.</span> <span class="nav-text">3、导入相应的库</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4%E3%80%81%E9%80%89%E6%8B%A9%E8%A7%86%E9%A2%91%E5%8F%8A%E6%A8%A1%E6%9D%BF"><span class="nav-number">3.1.5.</span> <span class="nav-text">4、选择视频及模板</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5%E3%80%81%E5%B0%86%E8%A7%86%E9%A2%91%E8%BD%AC%E5%8C%96%E4%B8%BA%E5%9B%BE%E7%89%87"><span class="nav-number">3.1.6.</span> <span class="nav-text">5、将视频转化为图片</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6%E3%80%81%E5%B0%86%E5%9B%BE%E7%89%87%E8%BD%AC%E6%8D%A2%E9%A3%8E%E6%A0%BC"><span class="nav-number">3.1.7.</span> <span class="nav-text">6、将图片转换风格</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7%E3%80%81%E5%B0%86%E5%9B%BE%E7%89%87%E5%90%88%E6%88%90%E4%B8%BA%E8%A7%86%E9%A2%91"><span class="nav-number">3.1.8.</span> <span class="nav-text">7、将图片合成为视频</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8%E3%80%81%E6%B7%BB%E5%8A%A0%E5%8E%9F%E6%9C%89%E9%9F%B3%E9%A2%91"><span class="nav-number">3.1.9.</span> <span class="nav-text">8、添加原有音频</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10%E3%80%81%E6%B8%85%E9%99%A4%E4%B8%B4%E6%97%B6%E6%95%B0%E6%8D%AE"><span class="nav-number">3.1.10.</span> <span class="nav-text">10、清除临时数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%B3%E4%BA%8E%E4%BD%9C%E8%80%85"><span class="nav-number">3.1.11.</span> <span class="nav-text">关于作者</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%97%AE%E9%A2%98"><span class="nav-number">3.2.</span> <span class="nav-text">问题</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8-Github-%E4%B8%8A%E7%9A%84%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE-%E5%A4%B1%E8%B4%A5"><span class="nav-number">4.</span> <span class="nav-text">使用 Github 上的开源项目 (失败)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#animegan2-pytorch"><span class="nav-number">4.1.</span> <span class="nav-text">animegan2-pytorch</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Fast-Style-Transfer-in-TensorFlow"><span class="nav-number">4.2.</span> <span class="nav-text">Fast Style Transfer in TensorFlow</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CCPL"><span class="nav-number">4.3.</span> <span class="nav-text">CCPL</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8-AnimeGANv3"><span class="nav-number">5.</span> <span class="nav-text">使用 AnimeGANv3</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AD%A5%E9%AA%A4"><span class="nav-number">5.1.</span> <span class="nav-text">步骤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">5.2.</span> <span class="nav-text">存在的问题</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8-DCT-Net"><span class="nav-number">6.</span> <span class="nav-text">使用 DCT-Net</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#SageMaker-%E5%A4%B1%E8%B4%A5"><span class="nav-number">6.1.</span> <span class="nav-text">SageMaker (失败)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kaggle"><span class="nav-number">6.2.</span> <span class="nav-text">kaggle</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93%E4%B8%8E%E5%8F%8D%E6%80%9D"><span class="nav-number">6.3.</span> <span class="nav-text">总结与反思</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Hetan</p>
  <div class="site-description" itemprop="description">普普通通研究生</div>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/hetan697" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;hetan697" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://hetan697.github.io/blogs/daily/2022/08/14/162312/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Hetan">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hetan的博客">
      <meta itemprop="description" content="普普通通研究生">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="When we disco 三渲二 | Hetan的博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          When we disco 三渲二
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-08-14 16:23:12" itemprop="dateCreated datePublished" datetime="2022-08-14T16:23:12+08:00">2022-08-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2023-01-28 16:08:57" itemprop="dateModified" datetime="2023-01-28T16:08:57+08:00">2023-01-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/daily/" itemprop="url" rel="index"><span itemprop="name">日常</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>介绍了将 When we disco 三渲二的历程主要步骤与相关问题，成功的有 <a href="#%E4%BD%BF%E7%94%A8-animeganv3">AnimeGANv3</a> 和 <a href="#kaggle">DCT-Net</a>。文章全文偏长，没用的失败经历居多；如时间紧迫，只看上述成功的两节即可。</p>
<span id="more"></span>

<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>在B站上看到别人把衿儿和粒粒跳的和嘉然和向晚跳的 When we disco 舞混剪，并冠以“三渲二”的名头。又发现 B 站上还没有衿使用 GAN 生成动画化衿儿和粒粒跳舞视频的实例，只在贴吧上看到过有画师将他们跳的舞画下来，而且画得还挺好看。想借助 GAN 动画化视频并投稿至 B 站的念头由此萌生。</p>
<p><img src="/blogs/daily/2022/08/14/162312/example.jpg" alt="paint_cover"></p>
<h2 id="使用-Deep-Dream-Generator-失败"><a href="#使用-Deep-Dream-Generator-失败" class="headerlink" title="使用 Deep Dream Generator (失败)"></a>使用 Deep Dream Generator (失败)</h2><p>通过百度得知<a target="_blank" rel="noopener" href="https://deepdreamgenerator.com/generator">deepdreamgenerator</a>是一个知名的风格迁移网站，可以轻松地对某一张照片进行操作，于是我注册了一个 deepdream 账户。进入网页后很快发现了两个问题：</p>
<ol>
<li>服务器架设在国外，国内访问速度慢。</li>
<li>网页上的模型只支持单张照片而不支持一整个视频。</li>
</ol>
<h2 id="使用-AnimeGANv2-失败"><a href="#使用-AnimeGANv2-失败" class="headerlink" title="使用 AnimeGANv2 (失败)"></a>使用 AnimeGANv2 (失败)</h2><p>我拿到这个问题后最先想到的其实就是<code>PaddlePaddle</code>，因为之前在<code>PaddlePaddle</code>上做过类似的项目，一整个体验非常不错。于是果不其然我找到了<a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/projectdetail/4422483?contributionType=1">PaddleHub一键视频动漫化</a>这个项目。</p>
<h3 id="paddle-代码"><a href="#paddle-代码" class="headerlink" title="paddle 代码"></a>paddle 代码</h3><hr>
<h4 id="0、BUG"><a href="#0、BUG" class="headerlink" title="0、BUG"></a>0、BUG</h4><p>在生成新版本时候，空文件夹无法加入，即使加入成功后，别人fork也无法显示。望修复，谢谢:)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!mkdir -p work/mp4_img work/mp4_img3 work/output</span><br></pre></td></tr></table></figure>

<h4 id="1、安装PaddleHub"><a href="#1、安装PaddleHub" class="headerlink" title="1、安装PaddleHub"></a>1、安装PaddleHub</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install paddlehub -U -i https://pypi.tuna.tsinghua.edu.cn/simple <span class="comment">#用了清华的镜像源</span></span><br></pre></td></tr></table></figure>

<p>   Looking in indexes: <a target="_blank" rel="noopener" href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a><br>   Requirement already satisfied: paddlehub in &#x2F;opt&#x2F;conda&#x2F;envs&#x2F;python35-paddle120-env&#x2F;lib&#x2F;python3.7&#x2F;site-packages (2.2.0)<br>   …<br>   （为节省版面删去刷屏部分）</p>
<h4 id="2、设置GPU环境"><a href="#2、设置GPU环境" class="headerlink" title="2、设置GPU环境"></a>2、设置GPU环境</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">%env CUDA_VISIBLE_DEVICES=<span class="number">0</span></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>

<blockquote>
<p><code>env: CUDA_VISIBLE_DEVICES=0</code></p>
</blockquote>
<h4 id="3、导入相应的库"><a href="#3、导入相应的库" class="headerlink" title="3、导入相应的库"></a>3、导入相应的库</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> paddlehub <span class="keyword">as</span> hub</span><br><span class="line"><span class="keyword">import</span> os</span><br></pre></td></tr></table></figure>

<h4 id="4、选择视频及模板"><a href="#4、选择视频及模板" class="headerlink" title="4、选择视频及模板"></a>4、选择视频及模板</h4><p><strong>Tips：可在此处更改风格哦</strong></p>
<p>这里可以更换很多风格，想了解更多风格，<a target="_blank" rel="noopener" href="https://www.paddlepaddle.org.cn/hublist?filter=en_category&value=GANs">请点击此处</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># input_video = &#x27;test.mp4&#x27;</span></span><br><span class="line">input_video = <span class="string">&#x27;test2.flv&#x27;</span></span><br><span class="line">model = hub.Module(name=<span class="string">&#x27;animegan_v2_shinkai_33&#x27;</span>, use_gpu=<span class="literal">True</span>) <span class="comment">#这里用的是animegan_v2_shinkai_33(新海诚动漫风格)</span></span><br></pre></td></tr></table></figure>

<blockquote>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[2022-08-12 16:53:29,855] [ WARNING] - The _initialize method in HubModule will soon be deprecated, you can use the __init__() to handle the initialization of the object</span><br><span class="line">E0812 16:53:29.861804  1550 analysis_config.cc:80] Please compile with gpu to EnableGpu()</span><br><span class="line">W0812 16:53:29.861893  1550 analysis_predictor.cc:1145] Deprecated. Please use CreatePredictor instead.</span><br></pre></td></tr></table></figure>
</blockquote>
<h4 id="5、将视频转化为图片"><a href="#5、将视频转化为图片" class="headerlink" title="5、将视频转化为图片"></a>5、将视频转化为图片</h4><p>Tips：可以用<code>ls work/mp4_img | wc -w</code>命令到终端看一下完成的图片数量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">transform_video_to_image</span>(<span class="params">video_file_path, img_path</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    将视频中每一帧保存成图片</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    video_capture = cv2.VideoCapture(video_file_path)</span><br><span class="line">    fps = video_capture.get(cv2.CAP_PROP_FPS)</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">        ret, frame = video_capture.read() </span><br><span class="line">        <span class="keyword">if</span> ret:</span><br><span class="line">            cv2.imwrite(img_path + <span class="string">&#x27;%d.jpg&#x27;</span> % count, frame)</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    video_capture.release()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;视频图片保存成功, 共有 %d 张&#x27;</span> % count)</span><br><span class="line">    <span class="keyword">return</span> fps,count</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将视频中每一帧保存成图片</span></span><br><span class="line"><span class="comment"># fps,count = transform_video_to_image(input_video, &#x27;work/mp4_img/&#x27;)</span></span><br><span class="line">count = <span class="number">6832</span></span><br></pre></td></tr></table></figure>

<h4 id="6、将图片转换风格"><a href="#6、将图片转换风格" class="headerlink" title="6、将图片转换风格"></a>6、将图片转换风格</h4><p><em>备注：运行时间可能会很久哦</em></p>
<p>Tips：可以用<code>ls work/mp4_img3 | wc -w</code>命令到终端看一下完成的图片数量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_combine_img</span>(<span class="params">input_file_patha</span>):</span><br><span class="line">    <span class="comment">#Pathname=&quot;&quot;</span></span><br><span class="line">    output_file_path=<span class="string">&quot;work/mp4_img3/&quot;</span></span><br><span class="line">    input_file_path=<span class="string">&quot;work/mp4_img/&quot;</span>+input_file_patha</span><br><span class="line">    <span class="comment">#print(input_file_path)</span></span><br><span class="line">    <span class="comment">#print(output_file_path)</span></span><br><span class="line">    model.style_transfer(images=[cv2.imread(input_file_path)],visualization=<span class="literal">True</span>,output_dir=output_file_path)</span><br><span class="line">    <span class="comment"># result = model.style_transfer(images=[cv2.imread(input_file_path)],visualization=True,output_dir=output_file_path)</span></span><br><span class="line">    <span class="comment"># for root, dirs, files in os.walk(output_file_path):</span></span><br><span class="line">    <span class="comment">#     fils=files</span></span><br><span class="line">    <span class="comment"># files=&#x27;&#x27;.join(files)</span></span><br><span class="line">    <span class="comment"># #print(files)</span></span><br><span class="line">    <span class="comment"># dict1=&quot;mv &quot;+output_file_path+files+&quot; &quot;+output_file_path+input_file_patha</span></span><br><span class="line">    <span class="comment"># os.system(dict1)</span></span><br><span class="line">    <span class="comment"># dict1=&quot;cp &quot;+output_file_path+input_file_patha+&quot; &quot;+&quot;./work/mp4_img3/&quot;+input_file_patha</span></span><br><span class="line">    <span class="comment"># #print(dict1)</span></span><br><span class="line">    <span class="comment"># os.system(dict1)</span></span><br><span class="line">    <span class="comment"># os.system(&quot;rm -rf ./work/mp4_img2&quot;)</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># def transform():</span></span><br><span class="line"><span class="comment">#     os.system(&quot;mkdir ./work/mp4_img3&quot;)</span></span><br><span class="line"><span class="comment">#     for i in range(0,count):</span></span><br><span class="line"><span class="comment">#         name=str(i)+&quot;.jpg&quot;</span></span><br><span class="line"><span class="comment">#         print(name)</span></span><br><span class="line"><span class="comment">#         get_combine_img(name)</span></span><br><span class="line"><span class="comment">#     print(&#x27;视频图片转换成功, 共有 %d 张&#x27; % (i+1))</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">transform</span>():</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,count):</span><br><span class="line">        input_file_path = <span class="string">&quot;work/mp4_img/&quot;</span> + <span class="built_in">str</span>(i)+<span class="string">&quot;.jpg&quot;</span></span><br><span class="line">        output_file_path = <span class="string">&quot;work/mp4_img3/&quot;</span> + <span class="built_in">str</span>(i)+<span class="string">&quot;.jpg&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(input_file_path)</span><br><span class="line">        results = model.style_transfer(images=[cv2.imread(input_file_path)], output_dir=output_file_path)</span><br><span class="line">        <span class="built_in">print</span>(output_file_path)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;视频图片转换成功, 共有 %d 张&#x27;</span> % (i+<span class="number">1</span>))</span><br><span class="line">    <span class="comment"># get_combine_img(name)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">transform()</span><br></pre></td></tr></table></figure>

<blockquote>
<p><code>work/mp4_img/0.jpg</code></p>
</blockquote>
<h4 id="7、将图片合成为视频"><a href="#7、将图片合成为视频" class="headerlink" title="7、将图片合成为视频"></a>7、将图片合成为视频</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">combine_image_to_video</span>(<span class="params">comb_path, output_file_path, fps, is_print=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        合并图像到视频</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    fourcc = cv2.VideoWriter_fourcc(*<span class="string">&#x27;MP4V&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    file_items = os.listdir(comb_path)</span><br><span class="line">    file_len = <span class="built_in">len</span>(file_items)</span><br><span class="line">    <span class="comment"># print(comb_path, file_items)</span></span><br><span class="line">    <span class="keyword">if</span> file_len &gt; <span class="number">0</span> :</span><br><span class="line">        temp_img = cv2.imread(os.path.join(comb_path, file_items[<span class="number">0</span>]))</span><br><span class="line">        img_height, img_width = temp_img.shape[<span class="number">0</span>], temp_img.shape[<span class="number">1</span>]</span><br><span class="line">      </span><br><span class="line">        out = cv2.VideoWriter(output_file_path, fourcc, fps, (img_width, img_height))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(file_len):</span><br><span class="line">            pic_name = os.path.join(comb_path, <span class="built_in">str</span>(i)+<span class="string">&quot;.jpg&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> is_print:</span><br><span class="line">                <span class="built_in">print</span>(i+<span class="number">1</span>,<span class="string">&#x27;/&#x27;</span>, file_len, <span class="string">&#x27; &#x27;</span>, pic_name)</span><br><span class="line">            img = cv2.imread(pic_name)</span><br><span class="line">            out.write(img)</span><br><span class="line">        out.release()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line">final_name=<span class="string">&quot;work/output/&quot;</span>+time.strftime(<span class="string">&quot;%Y%m%d%H%M%S&quot;</span>, time.localtime())+<span class="string">&quot;.mp4&quot;</span></span><br><span class="line">tran_name=<span class="string">&quot;! ffmpeg -i work/mp4_analysis.mp4 -i work/video.mp3 -c copy &quot;</span>+final_name</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">combine_image_to_video(<span class="string">&#x27;work/mp4_img3/&#x27;</span>, <span class="string">&#x27;work/mp4_analysis.mp4&#x27;</span> ,fps)</span><br></pre></td></tr></table></figure>

<h4 id="8、添加原有音频"><a href="#8、添加原有音频" class="headerlink" title="8、添加原有音频"></a>8、添加原有音频</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">! ffmpeg -i test.mp4 -vn work/video.mp3</span><br><span class="line">os.system(tran_name)</span><br><span class="line"><span class="comment">#! ffmpeg -i work/mp4_analysis.mp4 -i work/video.mp3 -c copy output/mp4_analysis_result.mp4</span></span><br></pre></td></tr></table></figure>

<h4 id="10、清除临时数据"><a href="#10、清除临时数据" class="headerlink" title="10、清除临时数据"></a>10、清除临时数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">! rm -rf ./work/mp4_img/*</span><br><span class="line">! rm -rf ./work/mp4_img3/*</span><br><span class="line">! rm -rf ./work/video.mp3</span><br><span class="line">! rm -rf ./work/mp4_analysis.mp4</span><br></pre></td></tr></table></figure>

<h4 id="关于作者"><a href="#关于作者" class="headerlink" title="关于作者"></a>关于作者</h4><p>😃姓名：曾焯淇😃</p>
<p>😃学历：高中😃</p>
<p>😃From：广东 佛山（欢迎面基）😃</p>
<p>我在AI Studio上获得黄金等级，点亮3个徽章，来互关呀~ <a target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/personalcenter/thirdview/233221">https://aistudio.baidu.com/aistudio/personalcenter/thirdview/233221</a></p>
<hr>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>如果上述代码可以运行成功，恐怕这篇博客就不会这么长了——可惜它不能。每次运行到转换部分时，系统就会卡死，然后提示 kernel 自动重启，具体地说无法执行下述代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.style_transfer(images=[cv2.imread(input_file_path)],visualization=<span class="literal">True</span>,output_dir=output_file_path)</span><br></pre></td></tr></table></figure>

<p>首先排除代码问题。因为官方给的例子是这样的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 转换为新海诚《你的名字》、《天气之子》风格图片</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> paddlehub <span class="keyword">as</span> hub</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型加载</span></span><br><span class="line"><span class="comment"># use_gpu：是否使用GPU进行预测</span></span><br><span class="line">model = hub.Module(name=<span class="string">&#x27;animegan_v2_shinkai_33&#x27;</span>, use_gpu=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">result = model.style_transfer(images=[cv2.imread(<span class="string">&#x27;./test.jpg&#x27;</span>)],visualization=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>这个例子已经无法运行了：</p>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[2022-08-12 17:11:15,815] [ WARNING] - The _initialize method in HubModule will soon be deprecated, you can use the __init__() to handle the initialization of the object</span><br><span class="line">---------------------------------------------------------------------------ValueError Traceback (most recent call last)/tmp/ipykernel_93/2846720433.py in &lt;module&gt; 10 11 # 模型预测 ---&gt; 12 result = model.style_transfer(images=[cv2.imread(&#x27;./test.jpg&#x27;)],visualization=True) /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlehub/compat/paddle_utils.py in runner(*args, **kwargs) 218 def runner(*args, **kwargs): 219 with static_mode_guard(): --&gt; 220 return func(*args, **kwargs) 221 222 return runner ~/.paddlehub/modules/animegan_v1_hayao_60/module.py in style_transfer(self, images, paths, output_dir, visualization, min_size, max_size) 44 45 # 模型预测 ---&gt; 46 outputs = self.model.predict(processor.input_datas) 47 48 # 结果后处理 ~/.paddlehub/modules/animegan_v1_hayao_60/model.py in predict(self, input_datas) 56 for input_data in input_datas: 57 self.input_tensor.copy_from_cpu(input_data) ---&gt; 58 self.predictor.zero_copy_run() 59 output = self.output_tensor.copy_to_cpu() 60 outputs.append(output) ValueError: In user code: File &quot;c:\users\xpk22\appdata\local\programs\python\python37\lib\site-packages\paddle\fluid\framework.py&quot;, line 2610, in append_op attrs=kwargs.get(&quot;attrs&quot;, None)) File &quot;c:\users\xpk22\appdata\local\programs\python\python37\lib\site-packages\paddle\fluid\layer_helper.py&quot;, line 43, in append_op return self.main_program.current_block().append_op(*args, **kwargs) File &quot;c:\users\xpk22\appdata\local\programs\python\python37\lib\site-packages\paddle\fluid\layers\nn.py&quot;, line 2938, in conv2d &quot;data_format&quot;: data_format, File &quot;Hayao-60\model_with_code\x2paddle_model.py&quot;, line 138, in x2paddle_net generator_G_MODEL_b1_Conv_Conv2D = fluid.layers.conv2d(input=conv2d_transpose_0, bias_attr=False, param_attr=&#x27;generator_G_MODEL_b1_Conv_weights&#x27;, num_filters=64, filter_size=[3, 3], stride=[1, 1], dilation=[1, 1], padding=&#x27;VALID&#x27;) File &quot;c:\users\xpk22\appdata\local\programs\python\python37\lib\site-packages\x2paddle\core\program.py&quot;, line 290, in gen_model inputs, outputs = x2paddle_model.x2paddle_net() File &quot;c:\users\xpk22\appdata\local\programs\python\python37\lib\site-packages\x2paddle\convert.py&quot;, line 137, in tf2paddle program.gen_model(save_dir) File &quot;c:\users\xpk22\appdata\local\programs\python\python37\lib\site-packages\x2paddle\convert.py&quot;, line 291, in main define_input_shape, params_merge) File &quot;C:\Users\Xpk22\AppData\Local\Programs\Python\Python37\Scripts\x2paddle.exe\__main__.py&quot;, line 7, in &lt;module&gt; sys.exit(main()) File &quot;c:\users\xpk22\appdata\local\programs\python\python37\lib\runpy.py&quot;, line 85, in _run_code exec(code, run_globals) File &quot;c:\users\xpk22\appdata\local\programs\python\python37\lib\runpy.py&quot;, line 193, in _run_module_as_main &quot;__main__&quot;, mod_spec) InvalidArgumentError: The number of input&#x27;s channels should be equal to filter&#x27;s channels * groups for Op(Conv). But received: the input&#x27;s channels is 674, the input&#x27;s shape is [1, 674, 1026, 3]; the filter&#x27;s channels is 3, the filter&#x27;s shape is [64, 3, 3, 3]; the groups is 1, the data_format is NCHW. The error may come from wrong data_format setting. [Hint: Expected input_channels == filter_dims[1] * groups, but received input_channels:674 != filter_dims[1] * groups:3.] (at /paddle/paddle/fluid/operators/conv_op.cc:116) [operator &lt; conv2d &gt; error]</span><br></pre></td></tr></table></figure>

<p>所以我猜测原因可能会是以下几点中的一点或多点：</p>
<ul>
<li><code>Paddle</code>框架存在不同版本间的兼容问题</li>
<li><code>AI Studio</code> 基础版运行环境给的内存太小</li>
<li><code>AI Studio</code> 基础版给的CPU太慢</li>
</ul>
<p>所以此次尝试是失败的。不过注意到它使用的模型是<code>AnimeGANv2</code>，这倒启发我去<a target="_blank" rel="noopener" href="https://github.com/">github</a>上找答案。于是，三下三下五除二找到了<a target="_blank" rel="noopener" href="https://github.com/bryandlee/animegan2-pytorch">AnimeGANv2</a>，于是有了后文。</p>
<h2 id="使用-Github-上的开源项目-失败"><a href="#使用-Github-上的开源项目-失败" class="headerlink" title="使用 Github 上的开源项目 (失败)"></a>使用 Github 上的开源项目 (失败)</h2><h3 id="animegan2-pytorch"><a href="#animegan2-pytorch" class="headerlink" title="animegan2-pytorch"></a>animegan2-pytorch</h3><p>在执行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#@title Face Detector &amp; FFHQ-style Alignment</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># https://github.com/woctezuma/stylegan2-projecting-images</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> dlib</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Union</span>, <span class="type">List</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_dlib_face_detector</span>(<span class="params">predictor_path: <span class="built_in">str</span> = <span class="string">&quot;shape_predictor_68_face_landmarks.dat&quot;</span></span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isfile(predictor_path):</span><br><span class="line">        model_file = <span class="string">&quot;shape_predictor_68_face_landmarks.dat.bz2&quot;</span></span><br><span class="line">        os.system(<span class="string">f&quot;wget http://dlib.net/files/<span class="subst">&#123;model_file&#125;</span>&quot;</span>)</span><br><span class="line">        os.system(<span class="string">f&quot;bzip2 -dk <span class="subst">&#123;model_file&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    detector = dlib.get_frontal_face_detector()</span><br><span class="line">    shape_predictor = dlib.shape_predictor(predictor_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">detect_face_landmarks</span>(<span class="params">img: <span class="type">Union</span>[Image.Image, np.ndarray]</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(img, Image.Image):</span><br><span class="line">            img = np.array(img)</span><br><span class="line">        faces = []</span><br><span class="line">        dets = detector(img)</span><br><span class="line">        <span class="keyword">for</span> d <span class="keyword">in</span> dets:</span><br><span class="line">            shape = shape_predictor(img, d)</span><br><span class="line">            faces.append(np.array([[v.x, v.y] <span class="keyword">for</span> v <span class="keyword">in</span> shape.parts()]))</span><br><span class="line">        <span class="keyword">return</span> faces</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> detect_face_landmarks</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">display_facial_landmarks</span>(<span class="params"></span></span><br><span class="line"><span class="params">    img: Image, </span></span><br><span class="line"><span class="params">    landmarks: <span class="type">List</span>[np.ndarray],</span></span><br><span class="line"><span class="params">    fig_size=[<span class="number">15</span>, <span class="number">15</span>]</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    plot_style = <span class="built_in">dict</span>(</span><br><span class="line">        marker=<span class="string">&#x27;o&#x27;</span>,</span><br><span class="line">        markersize=<span class="number">4</span>,</span><br><span class="line">        linestyle=<span class="string">&#x27;-&#x27;</span>,</span><br><span class="line">        lw=<span class="number">2</span></span><br><span class="line">    )</span><br><span class="line">    pred_type = collections.namedtuple(<span class="string">&#x27;prediction_type&#x27;</span>, [<span class="string">&#x27;slice&#x27;</span>, <span class="string">&#x27;color&#x27;</span>])</span><br><span class="line">    pred_types = &#123;</span><br><span class="line">        <span class="string">&#x27;face&#x27;</span>: pred_type(<span class="built_in">slice</span>(<span class="number">0</span>, <span class="number">17</span>), (<span class="number">0.682</span>, <span class="number">0.780</span>, <span class="number">0.909</span>, <span class="number">0.5</span>)),</span><br><span class="line">        <span class="string">&#x27;eyebrow1&#x27;</span>: pred_type(<span class="built_in">slice</span>(<span class="number">17</span>, <span class="number">22</span>), (<span class="number">1.0</span>, <span class="number">0.498</span>, <span class="number">0.055</span>, <span class="number">0.4</span>)),</span><br><span class="line">        <span class="string">&#x27;eyebrow2&#x27;</span>: pred_type(<span class="built_in">slice</span>(<span class="number">22</span>, <span class="number">27</span>), (<span class="number">1.0</span>, <span class="number">0.498</span>, <span class="number">0.055</span>, <span class="number">0.4</span>)),</span><br><span class="line">        <span class="string">&#x27;nose&#x27;</span>: pred_type(<span class="built_in">slice</span>(<span class="number">27</span>, <span class="number">31</span>), (<span class="number">0.345</span>, <span class="number">0.239</span>, <span class="number">0.443</span>, <span class="number">0.4</span>)),</span><br><span class="line">        <span class="string">&#x27;nostril&#x27;</span>: pred_type(<span class="built_in">slice</span>(<span class="number">31</span>, <span class="number">36</span>), (<span class="number">0.345</span>, <span class="number">0.239</span>, <span class="number">0.443</span>, <span class="number">0.4</span>)),</span><br><span class="line">        <span class="string">&#x27;eye1&#x27;</span>: pred_type(<span class="built_in">slice</span>(<span class="number">36</span>, <span class="number">42</span>), (<span class="number">0.596</span>, <span class="number">0.875</span>, <span class="number">0.541</span>, <span class="number">0.3</span>)),</span><br><span class="line">        <span class="string">&#x27;eye2&#x27;</span>: pred_type(<span class="built_in">slice</span>(<span class="number">42</span>, <span class="number">48</span>), (<span class="number">0.596</span>, <span class="number">0.875</span>, <span class="number">0.541</span>, <span class="number">0.3</span>)),</span><br><span class="line">        <span class="string">&#x27;lips&#x27;</span>: pred_type(<span class="built_in">slice</span>(<span class="number">48</span>, <span class="number">60</span>), (<span class="number">0.596</span>, <span class="number">0.875</span>, <span class="number">0.541</span>, <span class="number">0.3</span>)),</span><br><span class="line">        <span class="string">&#x27;teeth&#x27;</span>: pred_type(<span class="built_in">slice</span>(<span class="number">60</span>, <span class="number">68</span>), (<span class="number">0.596</span>, <span class="number">0.875</span>, <span class="number">0.541</span>, <span class="number">0.4</span>))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    fig = plt.figure(figsize=fig_size)</span><br><span class="line">    ax = fig.add_subplot(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    ax.imshow(img)</span><br><span class="line">    ax.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> face <span class="keyword">in</span> landmarks:</span><br><span class="line">        <span class="keyword">for</span> pred_type <span class="keyword">in</span> pred_types.values():</span><br><span class="line">            ax.plot(</span><br><span class="line">                face[pred_type.<span class="built_in">slice</span>, <span class="number">0</span>],</span><br><span class="line">                face[pred_type.<span class="built_in">slice</span>, <span class="number">1</span>],</span><br><span class="line">                color=pred_type.color, **plot_style</span><br><span class="line">            )</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># https://github.com/NVlabs/ffhq-dataset/blob/master/download_ffhq.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> PIL.Image</span><br><span class="line"><span class="keyword">import</span> PIL.ImageFile</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.ndimage</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">align_and_crop_face</span>(<span class="params"></span></span><br><span class="line"><span class="params">    img: Image.Image,</span></span><br><span class="line"><span class="params">    landmarks: np.ndarray,</span></span><br><span class="line"><span class="params">    expand: <span class="built_in">float</span> = <span class="number">1.0</span>,</span></span><br><span class="line"><span class="params">    output_size: <span class="built_in">int</span> = <span class="number">1024</span>, </span></span><br><span class="line"><span class="params">    transform_size: <span class="built_in">int</span> = <span class="number">4096</span>,</span></span><br><span class="line"><span class="params">    enable_padding: <span class="built_in">bool</span> = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    <span class="comment"># Parse landmarks.</span></span><br><span class="line">    <span class="comment"># pylint: disable=unused-variable</span></span><br><span class="line">    lm = landmarks</span><br><span class="line">    lm_chin          = lm[<span class="number">0</span>  : <span class="number">17</span>]  <span class="comment"># left-right</span></span><br><span class="line">    lm_eyebrow_left  = lm[<span class="number">17</span> : <span class="number">22</span>]  <span class="comment"># left-right</span></span><br><span class="line">    lm_eyebrow_right = lm[<span class="number">22</span> : <span class="number">27</span>]  <span class="comment"># left-right</span></span><br><span class="line">    lm_nose          = lm[<span class="number">27</span> : <span class="number">31</span>]  <span class="comment"># top-down</span></span><br><span class="line">    lm_nostrils      = lm[<span class="number">31</span> : <span class="number">36</span>]  <span class="comment"># top-down</span></span><br><span class="line">    lm_eye_left      = lm[<span class="number">36</span> : <span class="number">42</span>]  <span class="comment"># left-clockwise</span></span><br><span class="line">    lm_eye_right     = lm[<span class="number">42</span> : <span class="number">48</span>]  <span class="comment"># left-clockwise</span></span><br><span class="line">    lm_mouth_outer   = lm[<span class="number">48</span> : <span class="number">60</span>]  <span class="comment"># left-clockwise</span></span><br><span class="line">    lm_mouth_inner   = lm[<span class="number">60</span> : <span class="number">68</span>]  <span class="comment"># left-clockwise</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculate auxiliary vectors.</span></span><br><span class="line">    eye_left     = np.mean(lm_eye_left, axis=<span class="number">0</span>)</span><br><span class="line">    eye_right    = np.mean(lm_eye_right, axis=<span class="number">0</span>)</span><br><span class="line">    eye_avg      = (eye_left + eye_right) * <span class="number">0.5</span></span><br><span class="line">    eye_to_eye   = eye_right - eye_left</span><br><span class="line">    mouth_left   = lm_mouth_outer[<span class="number">0</span>]</span><br><span class="line">    mouth_right  = lm_mouth_outer[<span class="number">6</span>]</span><br><span class="line">    mouth_avg    = (mouth_left + mouth_right) * <span class="number">0.5</span></span><br><span class="line">    eye_to_mouth = mouth_avg - eye_avg</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Choose oriented crop rectangle.</span></span><br><span class="line">    x = eye_to_eye - np.flipud(eye_to_mouth) * [-<span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line">    x /= np.hypot(*x)</span><br><span class="line">    x *= <span class="built_in">max</span>(np.hypot(*eye_to_eye) * <span class="number">2.0</span>, np.hypot(*eye_to_mouth) * <span class="number">1.8</span>)</span><br><span class="line">    x *= expand</span><br><span class="line">    y = np.flipud(x) * [-<span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line">    c = eye_avg + eye_to_mouth * <span class="number">0.1</span></span><br><span class="line">    quad = np.stack([c - x - y, c - x + y, c + x + y, c + x - y])</span><br><span class="line">    qsize = np.hypot(*x) * <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Shrink.</span></span><br><span class="line">    shrink = <span class="built_in">int</span>(np.floor(qsize / output_size * <span class="number">0.5</span>))</span><br><span class="line">    <span class="keyword">if</span> shrink &gt; <span class="number">1</span>:</span><br><span class="line">        rsize = (<span class="built_in">int</span>(np.rint(<span class="built_in">float</span>(img.size[<span class="number">0</span>]) / shrink)), <span class="built_in">int</span>(np.rint(<span class="built_in">float</span>(img.size[<span class="number">1</span>]) / shrink)))</span><br><span class="line">        img = img.resize(rsize, PIL.Image.ANTIALIAS)</span><br><span class="line">        quad /= shrink</span><br><span class="line">        qsize /= shrink</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Crop.</span></span><br><span class="line">    border = <span class="built_in">max</span>(<span class="built_in">int</span>(np.rint(qsize * <span class="number">0.1</span>)), <span class="number">3</span>)</span><br><span class="line">    crop = (<span class="built_in">int</span>(np.floor(<span class="built_in">min</span>(quad[:,<span class="number">0</span>]))), <span class="built_in">int</span>(np.floor(<span class="built_in">min</span>(quad[:,<span class="number">1</span>]))), <span class="built_in">int</span>(np.ceil(<span class="built_in">max</span>(quad[:,<span class="number">0</span>]))), <span class="built_in">int</span>(np.ceil(<span class="built_in">max</span>(quad[:,<span class="number">1</span>]))))</span><br><span class="line">    crop = (<span class="built_in">max</span>(crop[<span class="number">0</span>] - border, <span class="number">0</span>), <span class="built_in">max</span>(crop[<span class="number">1</span>] - border, <span class="number">0</span>), <span class="built_in">min</span>(crop[<span class="number">2</span>] + border, img.size[<span class="number">0</span>]), <span class="built_in">min</span>(crop[<span class="number">3</span>] + border, img.size[<span class="number">1</span>]))</span><br><span class="line">    <span class="keyword">if</span> crop[<span class="number">2</span>] - crop[<span class="number">0</span>] &lt; img.size[<span class="number">0</span>] <span class="keyword">or</span> crop[<span class="number">3</span>] - crop[<span class="number">1</span>] &lt; img.size[<span class="number">1</span>]:</span><br><span class="line">        img = img.crop(crop)</span><br><span class="line">        quad -= crop[<span class="number">0</span>:<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Pad.</span></span><br><span class="line">    pad = (<span class="built_in">int</span>(np.floor(<span class="built_in">min</span>(quad[:,<span class="number">0</span>]))), <span class="built_in">int</span>(np.floor(<span class="built_in">min</span>(quad[:,<span class="number">1</span>]))), <span class="built_in">int</span>(np.ceil(<span class="built_in">max</span>(quad[:,<span class="number">0</span>]))), <span class="built_in">int</span>(np.ceil(<span class="built_in">max</span>(quad[:,<span class="number">1</span>]))))</span><br><span class="line">    pad = (<span class="built_in">max</span>(-pad[<span class="number">0</span>] + border, <span class="number">0</span>), <span class="built_in">max</span>(-pad[<span class="number">1</span>] + border, <span class="number">0</span>), <span class="built_in">max</span>(pad[<span class="number">2</span>] - img.size[<span class="number">0</span>] + border, <span class="number">0</span>), <span class="built_in">max</span>(pad[<span class="number">3</span>] - img.size[<span class="number">1</span>] + border, <span class="number">0</span>))</span><br><span class="line">    <span class="keyword">if</span> enable_padding <span class="keyword">and</span> <span class="built_in">max</span>(pad) &gt; border - <span class="number">4</span>:</span><br><span class="line">        pad = np.maximum(pad, <span class="built_in">int</span>(np.rint(qsize * <span class="number">0.3</span>)))</span><br><span class="line">        img = np.pad(np.float32(img), ((pad[<span class="number">1</span>], pad[<span class="number">3</span>]), (pad[<span class="number">0</span>], pad[<span class="number">2</span>]), (<span class="number">0</span>, <span class="number">0</span>)), <span class="string">&#x27;reflect&#x27;</span>)</span><br><span class="line">        h, w, _ = img.shape</span><br><span class="line">        y, x, _ = np.ogrid[:h, :w, :<span class="number">1</span>]</span><br><span class="line">        mask = np.maximum(<span class="number">1.0</span> - np.minimum(np.float32(x) / pad[<span class="number">0</span>], np.float32(w-<span class="number">1</span>-x) / pad[<span class="number">2</span>]), <span class="number">1.0</span> - np.minimum(np.float32(y) / pad[<span class="number">1</span>], np.float32(h-<span class="number">1</span>-y) / pad[<span class="number">3</span>]))</span><br><span class="line">        blur = qsize * <span class="number">0.02</span></span><br><span class="line">        img += (scipy.ndimage.gaussian_filter(img, [blur, blur, <span class="number">0</span>]) - img) * np.clip(mask * <span class="number">3.0</span> + <span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>)</span><br><span class="line">        img += (np.median(img, axis=(<span class="number">0</span>,<span class="number">1</span>)) - img) * np.clip(mask, <span class="number">0.0</span>, <span class="number">1.0</span>)</span><br><span class="line">        img = PIL.Image.fromarray(np.uint8(np.clip(np.rint(img), <span class="number">0</span>, <span class="number">255</span>)), <span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">        quad += pad[:<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Transform.</span></span><br><span class="line">    img = img.transform((transform_size, transform_size), PIL.Image.QUAD, (quad + <span class="number">0.5</span>).flatten(), PIL.Image.BILINEAR)</span><br><span class="line">    <span class="keyword">if</span> output_size &lt; transform_size:</span><br><span class="line">        img = img.resize((output_size, output_size), PIL.Image.ANTIALIAS)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure>

<p>中，报</p>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">---------------------------------------------------------------------------</span><br><span class="line">ModuleNotFoundError                       Traceback (most recent call last)</span><br><span class="line">/tmp/ipykernel_144/2320490344.py in &lt;module&gt;</span><br><span class="line">      4 </span><br><span class="line">      5 import os</span><br><span class="line">----&gt; 6 import dlib</span><br><span class="line">      7 import collections</span><br><span class="line">      8 from typing import Union, List</span><br><span class="line"></span><br><span class="line">ModuleNotFoundError: No module named &#x27;dlib&#x27;</span><br></pre></td></tr></table></figure>

<p>于是</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install dlib</span><br></pre></td></tr></table></figure>

<p>但</p>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">Collecting dlib</span><br><span class="line">  Using cached dlib-19.24.0.tar.gz (3.2 MB)</span><br><span class="line">  Preparing metadata (setup.py) ... done</span><br><span class="line">Building wheels for collected packages: dlib</span><br><span class="line">  Building wheel for dlib (setup.py) ... error</span><br><span class="line">  error: subprocess-exited-with-error</span><br><span class="line">  </span><br><span class="line">  × python setup.py bdist_wheel did not run successfully.</span><br><span class="line">  │ exit code: 1</span><br><span class="line">  ╰─&gt; [8 lines of output]</span><br><span class="line">      running bdist_wheel</span><br><span class="line">      running build</span><br><span class="line">      running build_py</span><br><span class="line">      package init file &#x27;tools/python/dlib/__init__.py&#x27; not found (or not a regular file)</span><br><span class="line">      running build_ext</span><br><span class="line">    </span><br><span class="line">      ERROR: CMake must be installed to build dlib</span><br><span class="line">    </span><br><span class="line">      [end of output]</span><br><span class="line">  </span><br><span class="line">  note: This error originates from a subprocess, and is likely not a problem with pip.</span><br><span class="line">  ERROR: Failed building wheel for dlib</span><br><span class="line">  Running setup.py clean for dlib</span><br><span class="line">Failed to build dlib</span><br><span class="line">Installing collected packages: dlib</span><br><span class="line">  Running setup.py install for dlib ... error</span><br><span class="line">  error: subprocess-exited-with-error</span><br><span class="line">  </span><br><span class="line">  × Running setup.py install for dlib did not run successfully.</span><br><span class="line">  │ exit code: 1</span><br><span class="line">  ╰─&gt; [10 lines of output]</span><br><span class="line">      running install</span><br><span class="line">      /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.</span><br><span class="line">        warnings.warn(</span><br><span class="line">      running build</span><br><span class="line">      running build_py</span><br><span class="line">      package init file &#x27;tools/python/dlib/__init__.py&#x27; not found (or not a regular file)</span><br><span class="line">      running build_ext</span><br><span class="line">    </span><br><span class="line">      ERROR: CMake must be installed to build dlib</span><br><span class="line">    </span><br><span class="line">      [end of output]</span><br><span class="line">  </span><br><span class="line">  note: This error originates from a subprocess, and is likely not a problem with pip.</span><br><span class="line">error: legacy-install-failure</span><br><span class="line"></span><br><span class="line">× Encountered error while trying to install package.</span><br><span class="line">╰─&gt; dlib</span><br><span class="line"></span><br><span class="line">note: This is an issue with the package mentioned above, not pip.</span><br><span class="line">hint: See above for output from the failure.</span><br><span class="line"></span><br><span class="line">[notice] A new release of pip available: 22.1.2 -&gt; 22.2.2</span><br><span class="line">[notice] To update, run: pip install --upgrade pip</span><br></pre></td></tr></table></figure>

<p>于是我放弃了</p>
<h3 id="Fast-Style-Transfer-in-TensorFlow"><a href="#Fast-Style-Transfer-in-TensorFlow" class="headerlink" title="Fast Style Transfer in TensorFlow"></a>Fast Style Transfer in <a target="_blank" rel="noopener" href="https://github.com/tensorflow/tensorflow">TensorFlow</a></h3><p>这<a target="_blank" rel="noopener" href="https://github.com/lengstrom/fast-style-transfer">项目</a>的<code>ReadMe</code>中写得真好：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">### Stylizing Video</span></span><br><span class="line">Use <span class="code">`transform_video.py`</span> to transfer style into a video. Run <span class="code">`python transform_video.py`</span> to view all the possible parameters. Requires <span class="code">`ffmpeg`</span>. [<span class="string">More detailed documentation here</span>](<span class="link">docs.md#transform_videopy</span>). Example usage:</span><br><span class="line"></span><br><span class="line"><span class="code">    python transform_video.py --in-path path/to/input/vid.mp4 \</span></span><br><span class="line"><span class="code">      --checkpoint path/to/style/model.ckpt \</span></span><br><span class="line"><span class="code">      --out-path out/video.mp4 \</span></span><br><span class="line"><span class="code">      --device /gpu:0 \</span></span><br><span class="line"><span class="code">      --batch-size 4</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="section">### Requirements</span></span><br><span class="line">You will need the following to run the above:</span><br><span class="line"><span class="bullet">-</span> TensorFlow 0.11.0</span><br><span class="line"><span class="bullet">-</span> Python 2.7.9, Pillow 3.4.2, scipy 0.18.1, numpy 1.11.2</span><br><span class="line"><span class="bullet">-</span> If you want to train (and don&#x27;t want to wait for 4 months):</span><br><span class="line"><span class="bullet">  -</span> A decent GPU</span><br><span class="line"><span class="bullet">  -</span> All the required NVIDIA software to run TF on a GPU (cuda, etc)</span><br><span class="line"><span class="bullet">-</span> ffmpeg 3.1.3 if you want to stylize video</span><br></pre></td></tr></table></figure>

<p>细看：<code>Requirements</code>中<code>TensorFlow 0.11.0</code>太老了吧，算了算了；还有“<code>Models for evaluation are</code> <a target="_blank" rel="noopener" href="https://drive.google.com/drive/folders/0B9jhaT37ydSyRk9UX0wwX3BpMzQ?resourcekey=0-Z9LcNHC-BTB4feKwm4loXw&usp=sharing"><code>located here</code></a>”里面存放模型的链接打不开。</p>
<h3 id="CCPL"><a href="#CCPL" class="headerlink" title="CCPL"></a><a target="_blank" rel="noopener" href="https://github.com/JarrentWu1031/CCPL">CCPL</a></h3><p>项目<code>ReadMe</code>：</p>
<figure class="highlight md"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">### Pre-trained Models</span></span><br><span class="line"></span><br><span class="line">To use the pre-trained models, please download here [<span class="string">pre-trained models</span>](<span class="link">https://drive.google.com/drive/folders/1XxhpzFqCVvboIyXKLfb2ocJZabPYu3pi?usp=sharing</span>) and specify them during training (These pre-trained models are trained under pytorch-1.9.1 and torchvision-0.10.1)</span><br></pre></td></tr></table></figure>

<p>pre-trained models 无法下载。</p>
<h2 id="使用-AnimeGANv3"><a href="#使用-AnimeGANv3" class="headerlink" title="使用 AnimeGANv3"></a>使用 AnimeGANv3</h2><p>在AnimeGANv2项目主页中，发现了AnimeGANv3。<code>AnimeGANv3</code>是一个尚在研发之中的项目，根据其主页介绍可以发现它尚未开源，仅提供了几个<code>.exe</code>程序来制作 Demo。下面将利用这个项目制作视频。</p>
<h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ol>
<li><p>下载原视频</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dotnet tool install --global BBDown</span><br><span class="line">BBDown -tv https://www.bilibili.com/video/BV1SB4y1y7GQ</span><br></pre></td></tr></table></figure>
</li>
<li><p>下载<code>AnimeGANv3</code>项目。该项目内不直接提供源代码，但提供使用<code>pyinstaller</code>打包而成的可以直接进行图片与视频风格迁移的<code>.exe</code>程序</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/TachibanaYoshino/AnimeGANv3.git</span><br></pre></td></tr></table></figure>
</li>
<li><p>开始风格迁移。按软件界面提示操作，依次选择<code>Vedio2Anime</code>、<code>video</code>、<code>model</code>，等待亿下，直至转换完成即可。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./AnimeGANv3/AnimeGANv3.exe</span><br></pre></td></tr></table></figure></li>
</ol>
<p><img src="/blogs/daily/2022/08/14/162312/20220814_164614_image.png" alt="软件GUI"><br><img src="/blogs/daily/2022/08/14/162312/20220814_164429_image.png" alt="软件CLI"></p>
<h3 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h3><p>首先是转换之后的风格。以封面为例我们来看看问题所在：</p>
<ul>
<li>原封面：<br><img src="/blogs/daily/2022/08/14/162312/example_source.jpg" alt="cover"></li>
<li>转换后的封面：<br><img src="/blogs/daily/2022/08/14/162312/example_source_output.jpg" alt="animeganV3-cover"></li>
</ul>
<p>我们发现，图片右下角衿儿的嗨丝就像没有被GAN处理过一样。更糟糕的是，在 B 站压缩封面画质、移动端缩小展示大小后，生成的图片已实际与原图差别不大。同样的问题不止发生在封面，而是贯穿整个视频。作为比较，我们还将较早前<code>animegan</code>的<a target="_blank" rel="noopener" href="https://replicate.com/ptran1203/pytorch-animegan">模型</a>拿出来进行生成，缺陷部分未见明显改善。<br><img src="/blogs/daily/2022/08/14/162312/replicate-prediction-23anxtekzbewnhsuyumjnfclyy.png" alt="animegan-cover"><br>对于这一点，评论区的带火见仁见智，但是我觉得还是尽可能要改进一下的。</p>
<h2 id="使用-DCT-Net"><a href="#使用-DCT-Net" class="headerlink" title="使用 DCT-Net"></a>使用 DCT-Net</h2><p>就在 B 站上投完稿之后的第二天早上我便刷到了介绍阿里达摩院<a target="_blank" rel="noopener" href="https://www.modelscope.cn/#/models">modelscope</a>的视频，视频中不担介绍了<a target="_blank" rel="noopener" href="https://www.modelscope.cn/#/models">modelscope</a>，还介绍了<a target="_blank" rel="noopener" href="https://github.com/menyifang/DCT-Net">DCT-Net</a>。这次这个模型<a target="_blank" rel="noopener" href="https://modelscope.cn/#/models/damo/cv_unet_person-image-cartoon_compound-models/summary">宣传效果挺好</a>。用网页版 API 试了试最起码效果比<code>AnimeGANv3</code>好，所以我想着把之前的缺点改进一下。</p>
<h3 id="SageMaker-失败"><a href="#SageMaker-失败" class="headerlink" title="SageMaker (失败)"></a>SageMaker (失败)</h3><p>首先进入<a target="_blank" rel="noopener" href="https://studiolab.sagemaker.aws/users">Amazon SageMaker Studio Lab</a>，反手开干：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br></pre></td></tr></table></figure>

<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">---------------------------------------------------------------------------</span><br><span class="line">ImportError                               Traceback (most recent call last)</span><br><span class="line">/tmp/ipykernel_83/2736127408.py in &lt;module&gt;</span><br><span class="line">----&gt; 1 import cv2</span><br><span class="line">      2 import os</span><br><span class="line"></span><br><span class="line">~/.conda/envs/default/lib/python3.9/site-packages/cv2/__init__.py in &lt;module&gt;</span><br><span class="line">      6 import sys</span><br><span class="line">      7 </span><br><span class="line">----&gt; 8 from .cv2 import *</span><br><span class="line">      9 from .cv2 import _registerMatType</span><br><span class="line">     10 from . import mat_wrapper</span><br><span class="line"></span><br><span class="line">ImportError: libgthread-2.0.so.0: cannot open shared object file: No such file or directory</span><br></pre></td></tr></table></figure>

<p>网上一搜，反手一个</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get install libglib2.0-dev</span><br></pre></td></tr></table></figure>

<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)</span><br><span class="line">E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?</span><br></pre></td></tr></table></figure>

<p>再来：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install libglib2.0-dev</span><br></pre></td></tr></table></figure>

<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash: sudo: command not found</span><br></pre></td></tr></table></figure>

<p>没救了，opencv都导入不成功了，还是改<code>kaggle</code>吧。</p>
<h3 id="kaggle"><a href="#kaggle" class="headerlink" title="kaggle"></a>kaggle</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">for</span> dirname, _, filenames <span class="keyword">in</span> os.walk(<span class="string">&#x27;/kaggle/input&#x27;</span>):</span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> filenames:</span><br><span class="line">        <span class="built_in">print</span>(os.path.join(dirname, filename))</span><br></pre></td></tr></table></figure>

<blockquote>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/kaggle/input/draftmp4/whenwedisco.mp4</span><br><span class="line">/kaggle/input/draftmp4/example.jpg</span><br><span class="line">/kaggle/input/draftmp4/real.jpg</span><br></pre></td></tr></table></figure>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!mkdir -p ./mp4_img ./mp4_img3 ./output</span><br><span class="line">!pip install <span class="string">&quot;modelscope[cv]&quot;</span> -f https://modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html</span><br></pre></td></tr></table></figure>

<blockquote>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Looking in links: https://modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html</span><br><span class="line">Collecting modelscope[cv]</span><br><span class="line">  Downloading https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v0.3/modelscope-0.3.4-py3-none-any.whl (1.0 MB)</span><br><span class="line">  ...</span><br><span class="line">缩减输出清版面</span><br></pre></td></tr></table></figure>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">input_video = <span class="string">&#x27;../input/draftmp4/whenwedisco.mp4&#x27;</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">transform_video_to_image</span>(<span class="params">video_file_path, img_path</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    将视频中每一帧保存成图片</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    video_capture = cv2.VideoCapture(video_file_path)</span><br><span class="line">    fps = video_capture.get(cv2.CAP_PROP_FPS)</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">        ret, frame = video_capture.read() </span><br><span class="line">        <span class="keyword">if</span> ret:</span><br><span class="line">            cv2.imwrite(img_path + <span class="string">&#x27;%d.jpg&#x27;</span> % count, frame)</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    video_capture.release()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;视频图片保存成功, 共有 %d 张&#x27;</span> % count)</span><br><span class="line">    <span class="keyword">return</span> fps,count</span><br><span class="line"></span><br><span class="line">fps,count = transform_video_to_image(input_video, <span class="string">&#x27;./mp4_img/&#x27;</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p><code>视频图片保存成功, 共有 6832 张</code></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> modelscope.outputs <span class="keyword">import</span> OutputKeys</span><br><span class="line"><span class="keyword">from</span> modelscope.pipelines <span class="keyword">import</span> pipeline</span><br><span class="line"><span class="keyword">from</span> modelscope.utils.constant <span class="keyword">import</span> Tasks</span><br><span class="line"></span><br><span class="line">img_cartoon = pipeline(Tasks.image_portrait_stylization, </span><br><span class="line">                       model=<span class="string">&#x27;damo/cv_unet_person-image-cartoon_compound-models&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, count-<span class="number">1</span>):</span><br><span class="line">    result = img_cartoon(<span class="string">&#x27;./mp4_img/%d.jpg&#x27;</span> % i)</span><br><span class="line">    cv2.imwrite(<span class="string">&#x27;./mp4_img3/%d.jpg&#x27;</span> % i, result[OutputKeys.OUTPUT_IMG])</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;./mp4_img/%d.jpg&#x27;</span> % i)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;finished!&#x27;</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">2022-08-15 03:53:52,771 - modelscope - INFO - PyTorch version 1.11.0 Found.</span><br><span class="line">2022-08-15 03:53:52,776 - modelscope - INFO - TensorFlow version 2.6.4 Found.</span><br><span class="line">2022-08-15 03:53:52,777 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer</span><br><span class="line">...</span><br><span class="line">缩减输出清版面</span><br><span class="line">2022-08-15 03:54:42.831239: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.98GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">No face detected!</span><br><span class="line">./mp4_img/0.jpg</span><br><span class="line">...</span><br><span class="line">缩减输出清版面</span><br><span class="line">No face detected!</span><br><span class="line">finished!</span><br></pre></td></tr></table></figure>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">combine_image_to_video</span>(<span class="params">comb_path, output_file_path, fps, is_print=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        合并图像到视频</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    fourcc = cv2.VideoWriter_fourcc(*<span class="string">&#x27;mp4v&#x27;</span>)    </span><br><span class="line">    </span><br><span class="line">    file_items = os.listdir(comb_path)</span><br><span class="line">    file_len = <span class="built_in">len</span>(file_items)</span><br><span class="line">    <span class="comment"># print(comb_path, file_items)</span></span><br><span class="line">    <span class="keyword">if</span> file_len &gt; <span class="number">0</span> :</span><br><span class="line">        temp_img = cv2.imread(os.path.join(comb_path, file_items[<span class="number">0</span>]))</span><br><span class="line">        img_height, img_width = temp_img.shape[<span class="number">0</span>], temp_img.shape[<span class="number">1</span>]</span><br><span class="line">        </span><br><span class="line">        out = cv2.VideoWriter(output_file_path, fourcc, fps, (img_width, img_height))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(file_len):</span><br><span class="line">            pic_name = os.path.join(comb_path, <span class="built_in">str</span>(i)+<span class="string">&quot;.jpg&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> is_print:</span><br><span class="line">                <span class="built_in">print</span>(i+<span class="number">1</span>,<span class="string">&#x27;/&#x27;</span>, file_len, <span class="string">&#x27; &#x27;</span>, pic_name)</span><br><span class="line">            img = cv2.imread(pic_name)</span><br><span class="line">            out.write(img)</span><br><span class="line">        out.release()</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">combine_image_to_video(<span class="string">&#x27;./mp4_img3/&#x27;</span>, <span class="string">&#x27;./output/mp4_analysis.mp4&#x27;</span> ,fps)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;finished!&quot;</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p><code>finished!</code></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line">final_name=<span class="string">&quot;./output/&quot;</span>+time.strftime(<span class="string">&quot;%Y%m%d%H%M%S&quot;</span>, time.localtime())+<span class="string">&quot;.mp4&quot;</span></span><br><span class="line">tran_name=<span class="string">&quot;! ffmpeg -i ./mp4_analysis.mp4 -i ./output/mp4_analysis.mp3 -c copy &quot;</span>+final_name</span><br><span class="line">! ffmpeg -i ../<span class="built_in">input</span>/draftmp4/whenwedisco.mp4 -vn ./output/mp4_analysis.mp3</span><br><span class="line">os.system(tran_name)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;finished!&quot;</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers</span><br><span class="line">  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)</span><br><span class="line">  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared</span><br><span class="line">  libavutil      56. 31.100 / 56. 31.100</span><br><span class="line">  libavcodec     58. 54.100 / 58. 54.100</span><br><span class="line">  libavformat    58. 29.100 / 58. 29.100</span><br><span class="line">  libavdevice    58.  8.100 / 58.  8.100</span><br><span class="line">  libavfilter     7. 57.100 /  7. 57.100</span><br><span class="line">  libavresample   4.  0.  0 /  4.  0.  0</span><br><span class="line">  libswscale      5.  5.100 /  5.  5.100</span><br><span class="line">  libswresample   3.  5.100 /  3.  5.100</span><br><span class="line">  libpostproc    55.  5.100 / 55.  5.100</span><br><span class="line">Input #0, mov,mp4,m4a,3gp,3g2,mj2, from &#x27;../input/draftmp4/whenwedisco.mp4&#x27;:</span><br><span class="line">  Metadata:</span><br><span class="line">    major_brand     : isom</span><br><span class="line">    minor_version   : 512</span><br><span class="line">    compatible_brands: isomiso2avc1mp41</span><br><span class="line">    encoder         : Lavf58.76.100</span><br><span class="line">    description     : Bilibili VXCode Swarm Transcoder v0.7.17</span><br><span class="line">  Duration: 00:03:48.07, start: 0.000000, bitrate: 6469 kb/s</span><br><span class="line">    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709), 1920x1080, 6334 kb/s, 29.97 fps, 29.97 tbr, 30k tbn, 59.94 tbc (default)</span><br><span class="line">    Metadata:</span><br><span class="line">      handler_name    : VideoHandler</span><br><span class="line">    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)</span><br><span class="line">    Metadata:</span><br><span class="line">      handler_name    : SoundHandler</span><br><span class="line">Stream mapping:</span><br><span class="line">  Stream #0:1 -&gt; #0:0 (aac (native) -&gt; mp3 (libmp3lame))</span><br><span class="line">Press [q] to stop, [?] for help</span><br><span class="line">Output #0, mp3, to &#x27;./output/mp4_analysis.mp3&#x27;:</span><br><span class="line">  Metadata:</span><br><span class="line">    major_brand     : isom</span><br><span class="line">    minor_version   : 512</span><br><span class="line">    compatible_brands: isomiso2avc1mp41</span><br><span class="line">    description     : Bilibili VXCode Swarm Transcoder v0.7.17</span><br><span class="line">    TSSE            : Lavf58.29.100</span><br><span class="line">    Stream #0:0(und): Audio: mp3 (libmp3lame), 44100 Hz, stereo, fltp (default)</span><br><span class="line">    Metadata:</span><br><span class="line">      handler_name    : SoundHandler</span><br><span class="line">      encoder         : Lavc58.54.100 libmp3lame</span><br><span class="line">size=    3564kB time=00:03:48.07 bitrate= 128.0kbits/s speed=  29x    </span><br><span class="line">video:0kB audio:3564kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.011508%</span><br><span class="line">finished!</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers</span><br><span class="line">  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)</span><br><span class="line">  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared</span><br><span class="line">  libavutil      56. 31.100 / 56. 31.100</span><br><span class="line">  libavcodec     58. 54.100 / 58. 54.100</span><br><span class="line">  libavformat    58. 29.100 / 58. 29.100</span><br><span class="line">  libavdevice    58.  8.100 / 58.  8.100</span><br><span class="line">  libavfilter     7. 57.100 /  7. 57.100</span><br><span class="line">  libavresample   4.  0.  0 /  4.  0.  0</span><br><span class="line">  libswscale      5.  5.100 /  5.  5.100</span><br><span class="line">  libswresample   3.  5.100 /  3.  5.100</span><br><span class="line">  libpostproc    55.  5.100 / 55.  5.100</span><br><span class="line">./mp4_analysis.mp4: No such file or directory</span><br></pre></td></tr></table></figure>
</blockquote>
<p>导出视频我们发现视频的码率不一，没办法，只能用格式工厂把转完之后的图像一帧一帧地合成视频后再用 Pr 调速度并添加音频后发布（直接用格式工厂加音频会出错），最后终于正常了。</p>
<h3 id="总结与反思"><a href="#总结与反思" class="headerlink" title="总结与反思"></a>总结与反思</h3><p>新模型是先对图片做 image segmentation 辨认人脸，再对人脸部分做 style transfer 。这样带来的问题是显而易见的：</p>
<p><img src="/blogs/daily/2022/08/14/162312/5421.jpg" alt="DCT缺点"></p>
<p>上图中，一张脸被 transfer 了而另一张脸没被 transfer。</p>
<p>先这样吧。后面实在不行改用 diffusion 的 generative 的 model 试试。</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="reward-container">
  <div>Buy me a coffee</div>
  <button>
    赞赏
  </button>
  <div class="post-reward">
      <div>
        <img src="/images/donate_wechatpay.png" alt="Hetan 微信">
        <span>微信</span>
      </div>
      <div>
        <img src="/images/donate_alipay.png" alt="Hetan 支付宝">
        <span>支付宝</span>
      </div>

  </div>
</div>

          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>Hetan
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="http://hetan697.github.io/blogs/daily/2022/08/14/162312/" title="When we disco 三渲二">http://hetan697.github.io/blogs/daily/2022/08/14/162312/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-CN" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/blogs/ml/SVM/2022/07/31/102218/" rel="prev" title="SVM简明教程">
                  <i class="fa fa-chevron-left"></i> SVM简明教程
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/blogs/dl/2022/09/09/151753/" rel="next" title="Pytorch入门1">
                  Pytorch入门1 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2022 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-face-kiss"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hetan</span>
</div>

    </div>
  </footer>

  

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"neutral","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/9.3.0/mermaid.min.js","integrity":"sha256-QdTG1YTLLTwD3b95jLqFxpQX9uYuJMNAtVZgwKX4oYU="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>



  




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"hetan697/hetan697.github.io","issue_term":"title","theme":"boxy-light"}</script>
<script src="/js/third-party/comments/utterances.js"></script>

</body>
</html>
